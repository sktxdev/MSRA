{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Machine Learning - NLTK</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code from https://github.com/shanglun/or_posts\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "# read in df\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# variety is a list of features, 2 words allowed, e.g., Fender Bender, Accident, Car Wreck etc.,\n",
    "# We can call this transaction type\n",
    "\n",
    "counter = Counter(df['transtype'].tolist())\n",
    "top_10_varieties = {i[0]: idx for idx, i in enumerate(counter.most_common(10))}\n",
    "df = df[df['transtype'].map(lambda x: x in top_10_varieties)]\n",
    "\n",
    "description_list = df['description'].tolist()\n",
    "varietal_list = [top_10_varieties[i] for i in df['transtype'].tolist()]\n",
    "varietal_list = np.array(varietal_list)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "x_train_counts = count_vect.fit_transform(description_list)\n",
    "\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "x_train_tfidf = tfidf_transformer.fit_transform(x_train_counts)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_train_tfidf, varietal_list, test_size=0.3)\n",
    "\n",
    "# Use this for a Support Vector Machine classifier\n",
    "# clf = SVC(kernel='linear').fit(train_x, train_y)\n",
    "\n",
    "# Use this for a multinomial naive Bayes classifier\n",
    "clf = MultinomialNB().fit(train_x, train_y)\n",
    "\n",
    "y_score = clf.predict(test_x)\n",
    "\n",
    "n_right = 0\n",
    "for i in range(len(y_score)):\n",
    "    if y_score[i] == test_y[i]:\n",
    "        n_right += 1\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % ((n_right/float(len(test_y)) * 100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear').fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# can put these into a lib folder\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from collections import defaultdict\n",
    "\n",
    "def count_top_x_words(corpus, top_x, skip_top_n):\n",
    "    count = defaultdict(lambda: 0)\n",
    "    for c in corpus:\n",
    "        for w in word_tokenize(c):\n",
    "            count[w] += 1\n",
    "    count_tuples = sorted([(w, c) for w, c in count.items()], key=lambda x: x[1], reverse=True)\n",
    "    return [i[0] for i in count_tuples[skip_top_n: skip_top_n + top_x]]\n",
    "\n",
    "\n",
    "def replace_top_x_words_with_vectors(corpus, top_x):\n",
    "    topx_dict = {top_x[i]: i for i in range(len(top_x))}\n",
    "\n",
    "    return [\n",
    "        [topx_dict[w] for w in word_tokenize(s) if w in topx_dict]\n",
    "        for s in corpus\n",
    "    ], topx_dict\n",
    "\n",
    "\n",
    "def filter_to_top_x(corpus, n_top, skip_n_top=0):\n",
    "    top_x = count_top_x_words(corpus, n_top, skip_n_top)\n",
    "    return replace_top_x_words_with_vectors(corpus, top_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras model with an embedding layer, a convolutional layer, \n",
    "# and a dense layer to take advantage of all of the deep learning features\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lib.get_top_xwords import filter_to_top_x\n",
    "\n",
    "df = pd.read_csv('data/wine_data.csv')\n",
    "\n",
    "counter = Counter(df['variety'].tolist())\n",
    "top_10_varieties = {i[0]: idx for idx, i in enumerate(counter.most_common(10))}\n",
    "df = df[df['variety'].map(lambda x: x in top_10_varieties)]\n",
    "\n",
    "description_list = df['description'].tolist()\n",
    "mapped_list, word_list = filter_to_top_x(description_list, 2500, 10)\n",
    "varietal_list_o = [top_10_varieties[i] for i in df['variety'].tolist()]\n",
    "varietal_list = to_categorical(varietal_list_o)\n",
    "\n",
    "max_review_length = 150\n",
    "\n",
    "mapped_list = sequence.pad_sequences(mapped_list, maxlen=max_review_length)\n",
    "train_x, test_x, train_y, test_y = train_test_split(mapped_list, varietal_list, test_size=0.3)\n",
    "\n",
    "max_review_length = 150\n",
    "\n",
    "embedding_vector_length = 64\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(2500, embedding_vector_length, input_length=max_review_length))\n",
    "model.add(Conv1D(50, 5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(max(varietal_list_o) + 1, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, epochs=3, batch_size=64)\n",
    "\n",
    "y_score = model.predict(test_x)\n",
    "y_score = [[1 if i == max(sc) else 0 for i in sc] for sc in y_score]\n",
    "n_right = 0\n",
    "for i in range(len(y_score)):\n",
    "    if all(y_score[i][j] == test_y[i][j] for j in range(len(y_score[i]))):\n",
    "        n_right += 1\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % ((n_right/float(len(test_y)) * 100)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
